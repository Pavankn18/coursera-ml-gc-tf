{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 2c. Loading large datasets progressively with the tf.data.Dataset </h1>\n",
    "\n",
    "In this notebook, we continue reading the same small dataset, but refactor our ML pipeline in two small, but significant, ways:\n",
    "<ol>\n",
    "<li> Refactor the input to read data from disk progressively.\n",
    "<li> Refactor the feature creation so that it is not one-to-one with inputs.\n",
    "</ol>\n",
    "<br/>\n",
    "The Pandas function in the previous notebook first read the whole data into memory -- on a large dataset, this won't be an option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "import datalab.bigquery as bq\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import shutil\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1. Refactor the input </h2>\n",
    "\n",
    "Read data created in Lab1a, but this time make it more general, so that we can later handle large datasets. We use the Dataset API for this. It ensures that, as data gets delivered to the model in mini-batches, it is loaded from disk only when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "DEFAULTS = [[0.0], [-74.0], [40.0], [-74.0], [40.7], [1.0], ['nokey']]\n",
    "\n",
    "def read_line(fileLine):\n",
    "  cols = tf.decode_csv(fileLine, record_defaults=DEFAULTS)\n",
    "  features = dict(zip(CSV_COLUMNS, cols))\n",
    "  features.pop(\"key\");\n",
    "  label = features.pop(\"fare_amount\")\n",
    "  return features, label\n",
    "\n",
    "# TODO: Create an appropriate input function read_dataset\n",
    "def read_dataset(filename, mode):\n",
    "    #TODO Add CSV decoder function and dataset creation and methods\n",
    "    dataset = tf.data.TextLineDataset(filename) \\\n",
    "      .map(read_line)\n",
    "    \n",
    "    batch = 250;\n",
    "    \n",
    "    if(mode == tf.estimator.ModeKeys.TRAIN):\n",
    "      num_epoch = None\n",
    "      dataset.shuffle(buffer_size = 1000)\n",
    "    else:\n",
    "      num_epoch = 1\n",
    "    return dataset.repeat(num_epoch).batch(batch)\n",
    "  \n",
    "def get_train_input_fn():\n",
    "  return read_dataset('./taxi-train.csv', mode = tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "def get_valid_input_fn():\n",
    "  return read_dataset('./taxi-valid.csv', mode = tf.estimator.ModeKeys.EVAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2. Refactor the way features are created. </h2>\n",
    "\n",
    "For now, pass these through (same as previous lab).  However, refactoring this way will enable us to break the one-to-one relationship between inputs and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_COLUMNS = [\n",
    "    tf.feature_column.numeric_column('pickuplon'),\n",
    "    tf.feature_column.numeric_column('pickuplat'),\n",
    "    tf.feature_column.numeric_column('dropofflat'),\n",
    "    tf.feature_column.numeric_column('dropofflon'),\n",
    "    tf.feature_column.numeric_column('passengers'),\n",
    "]\n",
    "\n",
    "def add_more_features(feats):\n",
    "  # Nothing to add (yet!)\n",
    "  return feats\n",
    "\n",
    "feature_cols = add_more_features(INPUT_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Create and train the model </h2>\n",
    "\n",
    "Note that we train for num_steps * batch_size examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_worker_replicas': 1, '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_save_summary_steps': 100, '_model_dir': 'taxi_trained', '_task_id': 0, '_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_is_chief': True, '_train_distribute': None, '_num_ps_replicas': 0, '_session_config': None, '_evaluation_master': '', '_service': None, '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd5d8142a90>, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 54896.812\n",
      "INFO:tensorflow:global_step/sec: 85.2857\n",
      "INFO:tensorflow:step = 101, loss = 25187.127 (1.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.5413\n",
      "INFO:tensorflow:step = 201, loss = 17412.402 (1.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.0593\n",
      "INFO:tensorflow:step = 301, loss = 22667.617 (1.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.5629\n",
      "INFO:tensorflow:step = 401, loss = 16351.827 (1.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.0832\n",
      "INFO:tensorflow:step = 501, loss = 14705.673 (1.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.8655\n",
      "INFO:tensorflow:step = 601, loss = 23771.123 (1.101 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.9002\n",
      "INFO:tensorflow:step = 701, loss = 19691.297 (1.100 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.6026\n",
      "INFO:tensorflow:step = 801, loss = 20453.67 (1.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.2685\n",
      "INFO:tensorflow:step = 901, loss = 24879.406 (1.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.069\n",
      "INFO:tensorflow:step = 1001, loss = 28042.777 (1.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.6775\n",
      "INFO:tensorflow:step = 1101, loss = 19108.586 (1.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 86.8917\n",
      "INFO:tensorflow:step = 1201, loss = 20217.533 (1.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.5856\n",
      "INFO:tensorflow:step = 1301, loss = 18137.1 (1.115 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.164\n",
      "INFO:tensorflow:step = 1401, loss = 17987.262 (1.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.1829\n",
      "INFO:tensorflow:step = 1501, loss = 20376.045 (1.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.0827\n",
      "INFO:tensorflow:step = 1601, loss = 21910.88 (1.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.7371\n",
      "INFO:tensorflow:step = 1701, loss = 11870.171 (1.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.0956\n",
      "INFO:tensorflow:step = 1801, loss = 21833.084 (1.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.1244\n",
      "INFO:tensorflow:step = 1901, loss = 18203.127 (1.109 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 26926.514.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x7fd5d8142f98>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "OUTDIR = 'taxi_trained'\n",
    "shutil.rmtree(OUTDIR, ignore_errors = True) # start fresh each time\n",
    "model = tf.estimator.LinearRegressor(\n",
    "      feature_columns = feature_cols, model_dir = OUTDIR)\n",
    "model.train(input_fn = get_train_input_fn, steps = 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Evaluate model </h3>\n",
    "\n",
    "As before, evaluate on the validation data.  We'll do the third refactoring (to move the evaluation into the training loop) in the next lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-25-17:36:44\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-25-17:36:44\n",
      "INFO:tensorflow:Saving dict for global step 2000: average_loss = 108.8457, global_step = 2000, loss = 25889.729\n",
      "RMSE on dataset = 10.432914733886719\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate(input_fn = get_valid_input_fn, steps = None)\n",
    "print('RMSE on dataset = {}'.format(np.sqrt(metrics['average_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge Exercise\n",
    "\n",
    "Create a neural network that is capable of finding the volume of a cylinder given the radius of its base (r) and its height (h). Assume that the radius and height of the cylinder are both in the range 0.5 to 2.0. Unlike in the challenge exercise for b_estimator.ipynb, assume that your measurements of r, h and V are all rounded off to the nearest 0.1. Simulate the necessary training dataset. This time, you will need a lot more data to get a good predictor.\n",
    "\n",
    "Hint (highlight to see):\n",
    "<p style='color:white'>\n",
    "Create random values for r and h and compute V. Then, round off r, h and V (i.e., the volume is computed from the true value of r and h; it's only your measurement that is rounded off). Your dataset will consist of the round values of r, h and V. Do this for both the training and evaluation datasets.\n",
    "</p>\n",
    "\n",
    "Now modify the \"noise\" so that instead of just rounding off the value, there is up to a 10% error (uniformly distributed) in the measurement followed by rounding off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "codeCollapsed": false,
    "hiddenCell": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_is_chief': True, '_evaluation_master': '', '_save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f905fe91128>, '_tf_random_seed': None, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_master': '', '_service': None, '_task_type': 'worker', '_log_step_count_steps': 100, '_keep_checkpoint_max': 5, '_save_summary_steps': 100, '_model_dir': 'DNNModel', '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_train_distribute': None, '_session_config': None, '_task_id': 0}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into DNNModel/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 29954648.0\n",
      "INFO:tensorflow:global_step/sec: 10.9847\n",
      "INFO:tensorflow:step = 101, loss = 27465644.0 (9.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9742\n",
      "INFO:tensorflow:step = 201, loss = 26440570.0 (9.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9643\n",
      "INFO:tensorflow:step = 301, loss = 25682742.0 (9.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0613\n",
      "INFO:tensorflow:step = 401, loss = 25063282.0 (9.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.908\n",
      "INFO:tensorflow:step = 501, loss = 24532018.0 (9.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9359\n",
      "INFO:tensorflow:step = 601, loss = 24063352.0 (9.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8993\n",
      "INFO:tensorflow:step = 701, loss = 23642024.0 (9.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9685\n",
      "INFO:tensorflow:step = 801, loss = 23258102.0 (9.117 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8819\n",
      "INFO:tensorflow:step = 901, loss = 22904740.0 (9.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.914\n",
      "INFO:tensorflow:step = 1001, loss = 22576844.0 (9.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8273\n",
      "INFO:tensorflow:step = 1101, loss = 22270596.0 (9.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0422\n",
      "INFO:tensorflow:step = 1201, loss = 21983170.0 (9.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0598\n",
      "INFO:tensorflow:step = 1301, loss = 21712174.0 (9.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0439\n",
      "INFO:tensorflow:step = 1401, loss = 21455660.0 (9.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4028\n",
      "INFO:tensorflow:step = 1501, loss = 21212146.0 (9.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6465\n",
      "INFO:tensorflow:step = 1601, loss = 20980250.0 (9.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8697\n",
      "INFO:tensorflow:step = 1701, loss = 20758980.0 (9.200 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0062\n",
      "INFO:tensorflow:step = 1801, loss = 20547308.0 (9.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9783\n",
      "INFO:tensorflow:step = 1901, loss = 20344420.0 (9.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3287\n",
      "INFO:tensorflow:step = 2001, loss = 20149688.0 (9.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0786\n",
      "INFO:tensorflow:step = 2101, loss = 19962376.0 (9.026 sec)\n",
      "INFO:tensorflow:global_step/sec: 6.50152\n",
      "INFO:tensorflow:step = 2201, loss = 19782008.0 (15.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.26749\n",
      "INFO:tensorflow:step = 2301, loss = 19608116.0 (18.985 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.53749\n",
      "INFO:tensorflow:step = 2401, loss = 19440250.0 (18.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.79975\n",
      "INFO:tensorflow:step = 2501, loss = 19277996.0 (11.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9259\n",
      "INFO:tensorflow:step = 2601, loss = 19121028.0 (9.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9321\n",
      "INFO:tensorflow:step = 2701, loss = 18969078.0 (9.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9165\n",
      "INFO:tensorflow:step = 2801, loss = 18821772.0 (9.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1553\n",
      "INFO:tensorflow:step = 2901, loss = 18678910.0 (8.966 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8174\n",
      "INFO:tensorflow:step = 3001, loss = 18540228.0 (9.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7969\n",
      "INFO:tensorflow:step = 3101, loss = 18405516.0 (9.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5373\n",
      "INFO:tensorflow:step = 3201, loss = 18274576.0 (9.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5716\n",
      "INFO:tensorflow:step = 3301, loss = 18147204.0 (9.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6019\n",
      "INFO:tensorflow:step = 3401, loss = 18023260.0 (9.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7176\n",
      "INFO:tensorflow:step = 3501, loss = 17902584.0 (9.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7526\n",
      "INFO:tensorflow:step = 3601, loss = 17785004.0 (9.299 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6453\n",
      "INFO:tensorflow:step = 3701, loss = 17670392.0 (9.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7853\n",
      "INFO:tensorflow:step = 3801, loss = 17558636.0 (9.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3841\n",
      "INFO:tensorflow:step = 3901, loss = 17449594.0 (9.631 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6175\n",
      "INFO:tensorflow:step = 4001, loss = 17343180.0 (9.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5045\n",
      "INFO:tensorflow:step = 4101, loss = 17239252.0 (9.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7063\n",
      "INFO:tensorflow:step = 4201, loss = 17137792.0 (9.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5398\n",
      "INFO:tensorflow:step = 4301, loss = 17038566.0 (9.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5517\n",
      "INFO:tensorflow:step = 4401, loss = 16941644.0 (9.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4034\n",
      "INFO:tensorflow:step = 4501, loss = 16846840.0 (9.610 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.022\n",
      "INFO:tensorflow:step = 4601, loss = 16754085.0 (9.981 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5884\n",
      "INFO:tensorflow:step = 4701, loss = 16663367.0 (9.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3598\n",
      "INFO:tensorflow:step = 4801, loss = 16574576.0 (9.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5531\n",
      "INFO:tensorflow:step = 4901, loss = 16487636.0 (9.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.91315\n",
      "INFO:tensorflow:step = 5001, loss = 16402482.0 (10.088 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3748\n",
      "INFO:tensorflow:step = 5101, loss = 16319132.0 (9.640 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.31344\n",
      "INFO:tensorflow:step = 5201, loss = 16237429.0 (10.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7724\n",
      "INFO:tensorflow:step = 5301, loss = 16157372.0 (9.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6739\n",
      "INFO:tensorflow:step = 5401, loss = 16078902.0 (9.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6192\n",
      "INFO:tensorflow:step = 5501, loss = 16001959.0 (9.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6052\n",
      "INFO:tensorflow:step = 5601, loss = 15926496.0 (9.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5992\n",
      "INFO:tensorflow:step = 5701, loss = 15852482.0 (9.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.951\n",
      "INFO:tensorflow:step = 5801, loss = 15779896.0 (9.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8837\n",
      "INFO:tensorflow:step = 5901, loss = 15708671.0 (9.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8485\n",
      "INFO:tensorflow:step = 6001, loss = 15638714.0 (9.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.837\n",
      "INFO:tensorflow:step = 6101, loss = 15570112.0 (9.228 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6140 into DNNModel/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 10.7993\n",
      "INFO:tensorflow:step = 6201, loss = 15502728.0 (9.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6533\n",
      "INFO:tensorflow:step = 6301, loss = 15436598.0 (9.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5007\n",
      "INFO:tensorflow:step = 6401, loss = 15371611.0 (9.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4272\n",
      "INFO:tensorflow:step = 6501, loss = 15307770.0 (9.589 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5317\n",
      "INFO:tensorflow:step = 6601, loss = 15245057.0 (9.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6178\n",
      "INFO:tensorflow:step = 6701, loss = 15183443.0 (9.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.4284\n",
      "INFO:tensorflow:step = 6801, loss = 15122925.0 (9.592 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5451\n",
      "INFO:tensorflow:step = 6901, loss = 15063412.0 (9.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6152\n",
      "INFO:tensorflow:step = 7001, loss = 15004956.0 (9.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5401\n",
      "INFO:tensorflow:step = 7101, loss = 14947450.0 (9.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 7201, loss = 14890891.0 (9.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3816\n",
      "INFO:tensorflow:step = 7301, loss = 14835328.0 (9.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5735\n",
      "INFO:tensorflow:step = 7401, loss = 14780637.0 (9.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6535\n",
      "INFO:tensorflow:step = 7501, loss = 14726869.0 (9.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7388\n",
      "INFO:tensorflow:step = 7601, loss = 14673994.0 (9.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6879\n",
      "INFO:tensorflow:step = 7701, loss = 14621941.0 (9.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5345\n",
      "INFO:tensorflow:step = 7801, loss = 14570758.0 (9.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.3397\n",
      "INFO:tensorflow:step = 7901, loss = 14520372.0 (9.671 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7519\n",
      "INFO:tensorflow:step = 8001, loss = 14470770.0 (9.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6431\n",
      "INFO:tensorflow:step = 8101, loss = 14421968.0 (9.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6871\n",
      "INFO:tensorflow:step = 8201, loss = 14373954.0 (9.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2524\n",
      "INFO:tensorflow:step = 8301, loss = 14326638.0 (9.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6092\n",
      "INFO:tensorflow:step = 8401, loss = 14280116.0 (9.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.764\n",
      "INFO:tensorflow:step = 8501, loss = 14234272.0 (9.290 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6309\n",
      "INFO:tensorflow:step = 8601, loss = 14189122.0 (9.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8091\n",
      "INFO:tensorflow:step = 8701, loss = 14144698.0 (9.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8397\n",
      "INFO:tensorflow:step = 8801, loss = 14100928.0 (9.230 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6488\n",
      "INFO:tensorflow:step = 8901, loss = 14057816.0 (9.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8271\n",
      "INFO:tensorflow:step = 9001, loss = 14015342.0 (9.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7636\n",
      "INFO:tensorflow:step = 9101, loss = 13973489.0 (9.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7776\n",
      "INFO:tensorflow:step = 9201, loss = 13932280.0 (9.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6929\n",
      "INFO:tensorflow:step = 9301, loss = 13891684.0 (9.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7006\n",
      "INFO:tensorflow:step = 9401, loss = 13851687.0 (9.344 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8495\n",
      "INFO:tensorflow:step = 9501, loss = 13812276.0 (9.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.683\n",
      "INFO:tensorflow:step = 9601, loss = 13773430.0 (9.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6344\n",
      "INFO:tensorflow:step = 9701, loss = 13735140.0 (9.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5616\n",
      "INFO:tensorflow:step = 9801, loss = 13697416.0 (9.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6132\n",
      "INFO:tensorflow:step = 9901, loss = 13660214.0 (9.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7851\n",
      "INFO:tensorflow:step = 10001, loss = 13623548.0 (9.272 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8704\n",
      "INFO:tensorflow:step = 10101, loss = 13587407.0 (9.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6966\n",
      "INFO:tensorflow:step = 10201, loss = 13551775.0 (9.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6232\n",
      "INFO:tensorflow:step = 10301, loss = 13516620.0 (9.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.6206\n",
      "INFO:tensorflow:step = 10401, loss = 13482025.0 (9.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8129\n",
      "INFO:tensorflow:step = 10501, loss = 13447848.0 (9.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7167\n",
      "INFO:tensorflow:step = 10601, loss = 13414191.0 (9.330 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8723\n",
      "INFO:tensorflow:step = 10701, loss = 13380988.0 (9.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.72\n",
      "INFO:tensorflow:step = 10801, loss = 13348229.0 (9.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8888\n",
      "INFO:tensorflow:step = 10901, loss = 13315941.0 (9.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.817\n",
      "INFO:tensorflow:step = 11001, loss = 13284074.0 (9.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8454\n",
      "INFO:tensorflow:step = 11101, loss = 13252659.0 (9.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.2489\n",
      "INFO:tensorflow:step = 11201, loss = 13221672.0 (9.758 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8407\n",
      "INFO:tensorflow:step = 11301, loss = 13191076.0 (9.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9734\n",
      "INFO:tensorflow:step = 11401, loss = 13160931.0 (9.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.7128\n",
      "INFO:tensorflow:step = 11501, loss = 13131182.0 (9.335 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5208\n",
      "INFO:tensorflow:step = 11601, loss = 13101812.0 (9.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9776\n",
      "INFO:tensorflow:step = 11701, loss = 13072846.0 (9.111 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.962\n",
      "INFO:tensorflow:step = 11801, loss = 13044263.0 (9.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.1492\n",
      "INFO:tensorflow:step = 11901, loss = 13016056.0 (8.960 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0653\n",
      "INFO:tensorflow:step = 12001, loss = 12988255.0 (9.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.9461\n",
      "INFO:tensorflow:step = 12101, loss = 12960796.0 (9.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0727\n",
      "INFO:tensorflow:step = 12201, loss = 12933702.0 (9.030 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.5619\n",
      "INFO:tensorflow:step = 12301, loss = 12906958.0 (9.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0072\n",
      "INFO:tensorflow:step = 12401, loss = 12880569.0 (9.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 11.0143\n",
      "INFO:tensorflow:step = 12501, loss = 12854520.0 (9.079 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 12564 into DNNModel/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 11.0299\n",
      "INFO:tensorflow:step = 12601, loss = 12828815.0 (9.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8631\n",
      "INFO:tensorflow:step = 12701, loss = 12803442.0 (9.206 sec)\n",
      "INFO:tensorflow:global_step/sec: 10.8729\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "import tensorflow as tf\n",
    "import shutil\n",
    "\n",
    "def calc_volume(r, h):\n",
    "  return 2*3.14*r*r*h\n",
    "\n",
    "feature_cols = [tf.feature_column.numeric_column(\"radius\"), tf.feature_column.numeric_column(\"height\")];\n",
    "\n",
    "def train_input_factory(limit):\n",
    "  def train_input_fn():\n",
    "    r = [0.5 + 0.01 * random.randint(1, 150) for i in range(limit)]\n",
    "    h = [0.5 + 0.01 * random.randint(1, 150) for i in range(limit)]\n",
    "    v = [ calc_volume(r1, h1) for r1, h1 in zip(r, h) ]\n",
    "\n",
    "    r1 = [round(i, 1) for i in r];\n",
    "    h1 = [round(i, 1) for i in h];\n",
    "    \n",
    "    features = { \"radius\": r, \"height\": h}\n",
    "    return features, v\n",
    "  return train_input_fn\n",
    "\n",
    "# shutil.rmtree(\"DNNModel\")\n",
    "model = tf.estimator.DNNRegressor(feature_columns = feature_cols, \n",
    "                                   hidden_units = [6,16,13,2],\n",
    "                                 model_dir = \"DNNModel\")\n",
    "\n",
    "model.train(train_input_factory(100000), steps=15000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "metrics = model.evaluate(input_fn = train_input_factory(100), steps=1);\n",
    "print(metrics)\n",
    "print('RMSE on dataset = {}'.format(np.sqrt(metrics['average_loss'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
